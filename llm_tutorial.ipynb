{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "This notebook demonstrates LangChain concepts using **local models via Ollama**. Before continuing, make sure the required models and Python packages are installed.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Install and Configure Ollama\n",
    "\n",
    "If you haven't already, install [Ollama](https://ollama.com) and ensure it's running locally.\n",
    "\n",
    "Then pull the required models:\n",
    "\n",
    "```bash\n",
    "ollama pull gemma3\n",
    "ollama pull nomic-embed-text\n",
    "```\n",
    "\n",
    "> These models will be used for generation (`gemma3`) and embeddings (`nomic-embed-text`).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Install Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install --upgrade pip --quiet\\n!pip install -U   langchain langchain-ollama langchain-community langchain-core   langchain-experimental chromadb pandas pymupdf ipython   duckduckgo-search --quiet\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install --upgrade pip --quiet\n",
    "!pip install -U \\\n",
    "  langchain langchain-ollama langchain-community langchain-core \\\n",
    "  langchain-experimental chromadb pandas pymupdf ipython \\\n",
    "  duckduckgo-search --quiet\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start Ollama (if not already running)\n",
    "\n",
    "Make sure Ollama is running in the background. You can check by running:\n",
    "\n",
    "```bash\n",
    "ollama list\n",
    "```\n",
    "\n",
    "This should list both `gemma3:latest` and `nomic-embed-text:latest` models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local vs. Cloud Models\n",
    "\n",
    "### Ollama (Local Execution)\n",
    "\n",
    "Ollama allows you to run open-source models (e.g., `gemma`, `llama`, `nomic-embed-text`) locally. This provides control, privacy, and fast iteration without API latency or cost.\n",
    "\n",
    "### Amazon Bedrock (Cloud Execution)\n",
    "\n",
    "[Amazon Bedrock](https://aws.amazon.com/bedrock/) provides access to multiple foundation models through a single API. It is fully managed, scalable, and integrates into AWS’s security and governance ecosystem.\n",
    "\n",
    "## Basic Concepts of Generative AI\n",
    "\n",
    "This section introduces core concepts for working with Large Language Models (LLMs), including how to prompt them effectively and build applications using frameworks like **LangChain**—whether deploying models locally via **Ollama** or through cloud services like **AWS Bedrock**.\n",
    "\n",
    "---\n",
    "\n",
    "### What Are LLMs?\n",
    "\n",
    "**Large Language Models (LLMs)** are machine learning models trained on massive text corpora. They predict the next token in a sequence based on context, making them powerful pattern-recognition tools for generating human-like text. However, they do not understand meaning or possess reasoning capabilities—their output is probabilistic, not factual by default.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompting and Prompt Engineering\n",
    "\n",
    "**Prompts** are structured inputs that tell an LLM what to do. A well-crafted prompt can significantly influence the quality, accuracy, and usefulness of the model's response.\n",
    "\n",
    "Prompts generally consist of three key components:\n",
    "\n",
    "---\n",
    "\n",
    "#### Instruction\n",
    "\n",
    "The **instruction** specifies the task or behavior expected from the model. It can be a simple question, a directive, or even a persona setup.\n",
    "\n",
    "**Examples:**\n",
    "- “Generate a list of known malicious domains associated with the Qakbot malware family.”\n",
    "- “Write a poem about the Qakbot malware family.”\n",
    "- “Produce a sonnet about my love of Franklin’s BBQ.”\n",
    "\n",
    "---\n",
    "\n",
    "#### Context\n",
    "\n",
    "**Context** includes relevant information provided to the model to help it complete the instruction. This is particularly important for specialized or domain-specific use cases.\n",
    "\n",
    "**Examples of context:**\n",
    "- Extracted text from a PDF or website\n",
    "- Lists of known facts or structured datasets\n",
    "- Internal business knowledge\n",
    "\n",
    "Context is critical when the model lacks the necessary background knowledge. It also enables **in-context learning** and is foundational to **RAG (Retrieval-Augmented Generation)** systems.\n",
    "\n",
    "**Reference:**  \n",
    "- [AWS Blog: Context Window Overflow – Breaking the Barrier](https://aws.amazon.com/blogs/security/context-window-overflow-breaking-the-barrier/)\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Format\n",
    "\n",
    "Defining the **output format** ensures the model returns a response in a structure that's compatible with downstream processing or presentation.\n",
    "\n",
    "**Examples:**\n",
    "- JSON/JSONL for programmatic consumption\n",
    "- Markdown for documentation or emails\n",
    "- Lists, CSV, or tabular formats for parsing\n",
    "\n",
    "Providing formatting examples in your prompt often leads to more consistent and usable output.\n",
    "\n",
    "---\n",
    "\n",
    "#### Best Practices for Prompt Engineering\n",
    "\n",
    "- Be explicit and unambiguous in your instructions.\n",
    "- Focus on what you want, not just what to avoid.\n",
    "- Supply sufficient context for the model to reason accurately.\n",
    "- Specify format, tone, language, or response length as needed.\n",
    "- Iterate and refine—prompt design is an interactive process.\n",
    "- Be cost-conscious—longer prompts and responses mean higher token usage.\n",
    "- Leverage in-context examples to teach the model new behavior.\n",
    "\n",
    "**Prompting strategies:**\n",
    "- **Zero-shot**: No examples provided.\n",
    "- **One-shot**: One example included.\n",
    "- **Few-shot**: Multiple examples included.\n",
    "\n",
    "---\n",
    "\n",
    "### System Prompts\n",
    "\n",
    "Some platforms (e.g., OpenAI, Anthropic) support **system prompts**—instructions that shape the model’s persona, tone, or behavioral constraints.\n",
    "\n",
    "**Example system message:**  \n",
    "> “You are a cybersecurity analyst generating threat intelligence summaries.”\n",
    "\n",
    "System prompts are not typically hidden; providers often document their usage:\n",
    "\n",
    "- [Anthropic: System Prompt Guidelines](https://docs.anthropic.com/en/release-notes/system-prompts)\n",
    "\n",
    "---\n",
    "\n",
    "### Fine-Tuning vs. In-Context Learning\n",
    "\n",
    "- **Fine-tuning** modifies the model’s internal weights using domain-specific data. It’s powerful but resource-intensive and harder to maintain.\n",
    "- **In-context learning** gives examples inline in the prompt. It’s flexible, efficient, and sufficient for many real-world use cases.\n",
    "\n",
    "---\n",
    "\n",
    "**Learn more:** [Prompt Engineering Guide](https://www.promptingguide.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core LangChain Concepts\n",
    "\n",
    "[LangChain](https://python.langchain.com/) is a modular framework for building generative AI applications powered by Large Language Models (LLMs). It simplifies the development of multi-step pipelines, retrieval-augmented workflows, and agent-based reasoning systems.\n",
    "\n",
    "---\n",
    "\n",
    "### LangChain Capabilities\n",
    "\n",
    "LangChain provides key building blocks for LLM applications:\n",
    "\n",
    "- **Prompt templates** for reusability and structure\n",
    "- **Memory** for multi-turn interactions\n",
    "- **Tools** to access external data sources\n",
    "- **Chains** to compose tasks in sequence or branching logic\n",
    "- **Agents** for dynamic tool use and reasoning\n",
    "- **Document loaders, chunkers, and retrievers** for knowledge ingestion\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt Templates\n",
    "\n",
    "**Prompt templates** allow you to define reusable prompts with variables. This is essential for consistent prompt formatting in production use cases.\n",
    "\n",
    "```python\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"Generate a list of domains associated with {malware_family}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(malware_family=\"Qakbot\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Memory\n",
    "\n",
    "LLMs are inherently **stateless**, meaning they do not retain context between interactions. LangChain provides memory modules such as `ConversationBufferMemory` that persist prior messages and automatically re-inject them into prompts.\n",
    "\n",
    "```python\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "```\n",
    "\n",
    "When used in a chain:\n",
    "\n",
    "```python\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory)\n",
    "```\n",
    "\n",
    "Memory is critical for applications like chatbots, copilots, or multi-turn reasoning agents.\n",
    "\n",
    "---\n",
    "\n",
    "### Tools\n",
    "\n",
    "**Tools** allow LLMs to interact with external systems—APIs, web search engines, internal databases, or third-party services. LangChain supports tool integration via descriptors that let agents reason about what tool to use and when.\n",
    "\n",
    "**Examples of tools:**\n",
    "- Google/Bing search\n",
    "- DomainTools, VirusTotal, Wikipedia\n",
    "- Custom internal APIs (e.g., threat intelligence, ticketing systems)\n",
    "\n",
    "More: [LangChain Tools Documentation](https://python.langchain.com/docs/modules/tools/)\n",
    "\n",
    "---\n",
    "\n",
    "### Chains\n",
    "\n",
    "**Chains** are workflows composed of modular steps. Each chain links one or more components (e.g., prompt → LLM → post-processor).\n",
    "\n",
    "Common chain types include:\n",
    "\n",
    "- `LLMChain`: single prompt-response (Note: LLMChain is deprecated in favor of LCEL - LangChain Expression Language)\n",
    "- `SimpleSequentialChain`: sequential chaining of steps\n",
    "- `MultiInputChain`: accepts multiple inputs\n",
    "- `RouterChain`: dynamically selects downstream chains based on input\n",
    "\n",
    "Example with memory:\n",
    "\n",
    "```python\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory=ConversationBufferMemory())\n",
    "```\n",
    "\n",
    "Chains provide structure and allow you to build reliable pipelines with conditional logic and state.\n",
    "\n",
    "---\n",
    "\n",
    "### Agents\n",
    "\n",
    "**Agents** enable dynamic, reasoning-driven workflows. Unlike static chains, agents interpret user input, determine which tools or sub-chains to invoke, gather additional data, and synthesize final responses.\n",
    "\n",
    "They excel at handling ambiguous prompts, complex logic, or open-ended tasks.\n",
    "\n",
    "More: [LangChain Agents Documentation](https://python.langchain.com/docs/modules/agents/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG and Embeddings\n",
    "\n",
    "### Vector Stores\n",
    "\n",
    "Vector databases (e.g., Chroma, FAISS, Pinecone) store **text embeddings**, which allow similarity searches against known documents or facts.\n",
    "\n",
    "### RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "**RAG** improves response quality by retrieving relevant content from an external knowledge source before prompting the model. This enables high-accuracy answers even from models that weren’t explicitly trained on the content.\n",
    "\n",
    "### Chunking\n",
    "\n",
    "Long documents are split into smaller **chunks** to improve retrieval accuracy and avoid exceeding token limits. LangChain includes text splitters like `RecursiveCharacterTextSplitter` that optimize chunk size and overlap.\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "Embeddings are numeric vectors that represent semantic meaning. They are used for similarity search in vector stores.\n",
    "\n",
    "- **Local**: e.g., `nomic-embed-text` via Ollama\n",
    "- **Cloud**: e.g., Titan via AWS Bedrock, HuggingFace SentenceTransformers\n",
    "\n",
    "---\n",
    "\n",
    "### LLM Limitations\n",
    "\n",
    "- **Hallucination**: Models may fabricate plausible but incorrect information.\n",
    "- **Context limitations**: Only a fixed number of tokens can be processed per prompt.\n",
    "- **Data leakage risk**: LLMs trained on sensitive data may inadvertently reveal it.\n",
    "- **Stateless**: Models forget previous interactions unless provided memory mechanisms.\n",
    "\n",
    "---\n",
    "\n",
    "### Understanding Tokenization\n",
    "\n",
    "LLMs process input/output as **tokens**, not words. Token count affects:\n",
    "\n",
    "- Cost (in usage-based billing models)\n",
    "- Whether your full prompt fits in the model’s context window\n",
    "- Output truncation risk\n",
    "\n",
    "Useful tools:\n",
    "- [Claude Tokenizer](https://claude-tokenizer.vercel.app/)\n",
    "- [TikToken Tokenizer](https://tiktikenizer.vercel.app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Ollama via LangChain - Zero Shot\n",
    "https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's talk about why the sky is blue! It’s a really fascinating phenomenon, and the short answer is due to something called **Rayleigh scattering**. Here’s a breakdown:\n",
       "\n",
       "**1. Sunlight and Colors:**\n",
       "\n",
       "* Sunlight appears white, but it’s actually made up of all the colors of the rainbow – red, orange, yellow, green, blue, indigo, and violet. Think of a prism splitting light.\n",
       "\n",
       "**2. Entering the Atmosphere:**\n",
       "\n",
       "* When sunlight enters the Earth’s atmosphere, it bumps into tiny air molecules (mostly nitrogen and oxygen).\n",
       "\n",
       "**3. Rayleigh Scattering – The Key!**\n",
       "\n",
       "* **Rayleigh scattering** is the scattering of electromagnetic radiation (like light) by particles of a much smaller wavelength.  In this case, the air molecules are much smaller than the wavelengths of visible light.\n",
       "* **Shorter wavelengths scatter more:**  Crucially, blue and violet light have shorter wavelengths than other colors. This means they are scattered *much* more strongly by these air molecules.  It’s like throwing a small ball (blue light) against a bumpy surface – it bounces off in all directions.  A larger ball (red light) would be less affected."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "# Note: Ensure Ollama is running locally and the gemma3 model is installed\n",
    "# Run: ollama pull gemma3\n",
    "# If Ollama is not running, you'll get a connection error\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3\",\n",
    "    temperature=0.8,\n",
    "    # base_url=\"http://remote-ip:port\", # Ollama default port: 11434\n",
    "    # timeout=5,\n",
    "    num_predict=256,  # Use num_predict instead of max_tokens for Ollama\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"why is the sky blue?\"),\n",
    "]\n",
    "\n",
    "Markdown(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prompt Templates and LangChain Expression Syntax\n",
    "\n",
    "This example introduces the use of a `ChatPromptTemplate` combined with an Ollama-backed LLM using LangChain's expression syntax. This pattern allows for reusable, parameterized prompts and demonstrates how to integrate structured prompting into your pipeline. The `|` operator chains the prompt and model together, creating a modular and declarative workflow.\n",
    "\n",
    "We’ll also simulate a multi-role setup (e.g., system + human) within the prompt string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's break down LummaC2 – it's a pretty nasty piece of malware that's been making waves in the cybersecurity world. Here's a step-by-step breakdown:\n",
       "\n",
       "**1. What is LummaC2?**\n",
       "\n",
       "LummaC2 (also known as \"NightSky\") is a sophisticated, multi-stage cyber espionage malware developed by the North Korean Lazarus Group. It’s a Command and Control (C2) infrastructure, meaning it’s the backbone of a cyberattack. It’s *not* a standalone virus that directly infects systems. Instead, it’s used to control and coordinate other malware that *does* infect systems.\n",
       "\n",
       "**2. Key Characteristics & Functionality:**\n",
       "\n",
       "* **Multi-Stage Architecture:** This is the most critical aspect. LummaC2 operates in three distinct stages:\n",
       "    * **Initial Access:**  Typically, LummaC2 gains initial access through phishing emails containing malicious documents (often Microsoft Office documents). These documents contain macros that, when enabled, trigger the download and execution of the initial LummaC2 components.\n",
       "    * **Beaconing & Data Exfiltration:** Once established, LummaC2 establishes a persistent connection (a \"beacon\") to a command server. It then gathers intelligence – usually targeting organizations in the finance, technology, and defense sectors. This intelligence can include sensitive information, intellectual property, and strategic planning details.\n",
       "    * **Secondary Malware Deployment:** This is where it gets really dangerous.  LummaC2 doesn't just collect data; it *actively* deploys secondary malware, often Cobalt Strike, to further compromise the victim’s network, spread laterally, and escalate privileges.\n",
       "\n",
       "* **Advanced Techniques:**\n",
       "    * **Dynamic DNS:** LummaC2 utilizes dynamic DNS services to constantly change its C2 server addresses, making it incredibly difficult to track and block.\n",
       "    * **SSL/TLS Encryption:** Communication between the beaconing agents and the C2 server is heavily encrypted using SSL/TLS, further obscuring the activity.\n",
       "    * **Staged Downloads:**  The malware is broken down into smaller, encrypted modules which are downloaded sequentially, making detection harder.\n",
       "    * **Use of Cryptocurrency:** The group uses cryptocurrency (primarily Bitcoin) to pay for services and to facilitate the exfiltration of stolen data.\n",
       "\n",
       "\n",
       "**3. Why it’s a Threat:**\n",
       "\n",
       "* **Sophisticated Threat Actor:**  It's operated by the Lazarus Group, a well-known and highly skilled cyber espionage unit affiliated with the North Korean government.  They're known for operations like the WannaCry ransomware attack and the Sony Pictures hack.\n",
       "* **Espionage Focused:** LummaC2's primary goal isn't typically financial gain (though that's a byproduct); it’s about gathering intelligence for strategic advantage.\n",
       "* **Ongoing Activity:**  LummaC2 is still actively being used in attacks, meaning organizations need to remain vigilant.\n",
       "\n",
       "**4.  AWS Relevance (as your AI assistant to AWS):**\n",
       "\n",
       "* **Threat Intelligence Integration:**  AWS services like GuardDuty and Security Hub regularly ingest threat intelligence feeds that include information about LummaC2.  You can configure these services to automatically detect and alert you to activity associated with LummaC2.\n",
       "* **Network Security:**  Ensure your VPCs, EC2 instances, and other AWS resources are properly configured with security groups and network ACLs to restrict inbound and outbound traffic, limiting the potential for LummaC2 to establish a beacon.\n",
       "* **Monitoring & Logging:**  Enable comprehensive logging and monitoring across your AWS environment to detect suspicious activity.  Analyze logs for unusual patterns of communication.\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "Do you want me to delve deeper into a specific aspect of LummaC2, such as:\n",
       "\n",
       "*   Its technical details (e.g., the malware's architecture)?\n",
       "*   How to detect it on AWS?\n",
       "*   Specific tactics, techniques, and procedures (TTPs) used by the Lazarus Group?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "Markdown(chain.invoke({\"question\": \"System: You are cybersecurity expert, and AI assisant to AWS.\\n\\nHuman: What is the LummaC2 malware?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "It's nice to be able to ask a question and get an answer, but that seems pretty transactional and impersonal. I'd like the LLM I'm talking to to show me they are listening to me and paying attention to what I am saying. I am, after all, human and I need to be loved or at least feel like it.\n",
    "\n",
    "But LLMs are cold and heartless (technically, they are stateless but we are talking about my feelings here). This means that they don’t ‘remember’ interactions from prompt to prompt. You can fine tune them to persist data but without updating the weights through expensive training but, they don’t ‘remember’ anything more after the model is set at a checkpoint. This means if I just asked what the Qakbot malware was and then follow up with a question like \"What industry was primarily targeted by this malware?\", the model will not be able to answer within the context of Qakbot...since show beats tell, let's see how that works firsthand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets ask the followup question..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, to help you determine which industry was primarily targeted by this malware, I need some information about the malware itself. Please tell me:\n",
       "\n",
       "*   **What is the name of the malware?** (e.g., WannaCry, NotPetya, Emotet, etc.)\n",
       "*   **What are its key characteristics?** (e.g., ransomware, banking trojan, spyware, etc.)\n",
       "*   **What is its primary method of infection?** (e.g., phishing emails, exploited vulnerabilities, drive-by downloads, etc.)\n",
       "*   **What are the known targets or affected sectors?** (e.g., hospitals, manufacturing, finance, government, etc.)\n",
       "\n",
       "The more detail you can provide, the more accurately I can pinpoint the industry that was primarily targeted. \n",
       "\n",
       "Once I have this information, I can give you a much more specific and helpful answer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm.invoke(\"System: You are cybersecurity expert, and AI assisant.\\n\\nHuman: What industry was primarily targeted by this malware?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Memory Components: Enabling Stateful Conversations\n",
    "The memory component of LangChain allows the LLM to become 'stateful'. This quality is quite useful when developing applications driven by LLMs. For instance, a conversational system or a chatbot is required to recall past interactions to maintain a conversation. Without memory, the system would not be able to handle follow-up messages or recollect key pieces of information mentioned earlier in the conversation. \n",
    "\n",
    "In this section, we will explore the memory modules provided by LangChain. LangChain offers several types of memory modules depending on the task and the properties of the LLM. We will incorporate memory into chains and examine changes in performance due to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize Ollama with Gemma model\n",
    "llm = Ollama(model=\"gemma3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "history",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "response",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8dfcf64d-4396-4a42-9578-87b83b5c62c7",
       "rows": [
        [
         "0",
         "What is the LummaC2 malware?",
         "{'history': \"Human: What is the LummaC2 malware?\\nAI: Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \\n\\nEssentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \\n\\nHere’s a breakdown of what it does and some of the specific details that have come to light:\\n\\n*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\\n    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\\n    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\\n    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\\n    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\\n\\n*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \\n\\n*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\\n\\n*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \\n\\nYou can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?\"}",
         "Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \n\nEssentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \n\nHere’s a breakdown of what it does and some of the specific details that have come to light:\n\n*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\n    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\n    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\n    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\n    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\n\n*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \n\n*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\n\n*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \n\nYou can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?"
        ],
        [
         "1",
         "What industry was primarily targeted by this malware?",
         "{'history': \"Human: What is the LummaC2 malware?\\nAI: Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \\n\\nEssentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \\n\\nHere’s a breakdown of what it does and some of the specific details that have come to light:\\n\\n*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\\n    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\\n    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\\n    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\\n    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\\n\\n*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \\n\\n*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\\n\\n*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \\n\\nYou can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?\\nHuman: What industry was primarily targeted by this malware?\\nAI: That’s a really good question! While LummaC2 has been observed targeting a *variety* of sectors, the technology, gaming, and cryptocurrency industries have been the most heavily targeted. \\n\\nSpecifically, it’s been frequently used against companies involved in cryptocurrency – think exchanges and wallet providers – likely to steal digital assets. We've seen a significant amount of activity directed at gaming companies, potentially related to intellectual property theft or financial gain through fraudulent activities. \\n\\nHowever, it’s important to note that its modular design and reconnaissance capabilities mean it *could* be used against any organization with valuable data, so the targets aren’t limited to just these three. Do you want me to elaborate on the specific tactics they’re using against each of those industries, or perhaps discuss the broader implications of this targeting?\"}",
         "That’s a really good question! While LummaC2 has been observed targeting a *variety* of sectors, the technology, gaming, and cryptocurrency industries have been the most heavily targeted. \n\nSpecifically, it’s been frequently used against companies involved in cryptocurrency – think exchanges and wallet providers – likely to steal digital assets. We've seen a significant amount of activity directed at gaming companies, potentially related to intellectual property theft or financial gain through fraudulent activities. \n\nHowever, it’s important to note that its modular design and reconnaissance capabilities mean it *could* be used against any organization with valuable data, so the targets aren’t limited to just these three. Do you want me to elaborate on the specific tactics they’re using against each of those industries, or perhaps discuss the broader implications of this targeting?"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>history</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the LummaC2 malware?</td>\n",
       "      <td>{'history': 'Human: What is the LummaC2 malware?\n",
       "AI: Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \n",
       "\n",
       "Essentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \n",
       "\n",
       "Here’s a breakdown of what it does and some of the specific details that have come to light:\n",
       "\n",
       "*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\n",
       "    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\n",
       "    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\n",
       "    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\n",
       "    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\n",
       "\n",
       "*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \n",
       "\n",
       "*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\n",
       "\n",
       "*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \n",
       "\n",
       "You can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?'}</td>\n",
       "      <td>Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \\n\\nEssentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \\n\\nHere’s a breakdown of what it does and some of the specific details that have come to light:\\n\\n*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\\n    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\\n    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\\n    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\\n    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\\n\\n*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \\n\\n*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\\n\\n*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \\n\\nYou can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What industry was primarily targeted by this malware?</td>\n",
       "      <td>{'history': 'Human: What is the LummaC2 malware?\n",
       "AI: Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \n",
       "\n",
       "Essentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \n",
       "\n",
       "Here’s a breakdown of what it does and some of the specific details that have come to light:\n",
       "\n",
       "*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\n",
       "    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\n",
       "    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\n",
       "    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\n",
       "    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\n",
       "\n",
       "*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \n",
       "\n",
       "*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\n",
       "\n",
       "*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \n",
       "\n",
       "You can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?\n",
       "Human: What industry was primarily targeted by this malware?\n",
       "AI: That’s a really good question! While LummaC2 has been observed targeting a *variety* of sectors, the technology, gaming, and cryptocurrency industries have been the most heavily targeted. \n",
       "\n",
       "Specifically, it’s been frequently used against companies involved in cryptocurrency – think exchanges and wallet providers – likely to steal digital assets. We've seen a significant amount of activity directed at gaming companies, potentially related to intellectual property theft or financial gain through fraudulent activities. \n",
       "\n",
       "However, it’s important to note that its modular design and reconnaissance capabilities mean it *could* be used against any organization with valuable data, so the targets aren’t limited to just these three. Do you want me to elaborate on the specific tactics they’re using against each of those industries, or perhaps discuss the broader implications of this targeting?'}</td>\n",
       "      <td>That’s a really good question! While LummaC2 has been observed targeting a *variety* of sectors, the technology, gaming, and cryptocurrency industries have been the most heavily targeted. \\n\\nSpecifically, it’s been frequently used against companies involved in cryptocurrency – think exchanges and wallet providers – likely to steal digital assets. We've seen a significant amount of activity directed at gaming companies, potentially related to intellectual property theft or financial gain through fraudulent activities. \\n\\nHowever, it’s important to note that its modular design and reconnaissance capabilities mean it *could* be used against any organization with valuable data, so the targets aren’t limited to just these three. Do you want me to elaborate on the specific tactics they’re using against each of those industries, or perhaps discuss the broader implications of this targeting?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input  \\\n",
       "0                           What is the LummaC2 malware?   \n",
       "1  What industry was primarily targeted by this malware?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 history  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'history': 'Human: What is the LummaC2 malware?\n",
       "AI: Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \n",
       "\n",
       "Essentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \n",
       "\n",
       "Here’s a breakdown of what it does and some of the specific details that have come to light:\n",
       "\n",
       "*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\n",
       "    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\n",
       "    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\n",
       "    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\n",
       "    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\n",
       "\n",
       "*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \n",
       "\n",
       "*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\n",
       "\n",
       "*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \n",
       "\n",
       "You can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?'}   \n",
       "1  {'history': 'Human: What is the LummaC2 malware?\n",
       "AI: Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \n",
       "\n",
       "Essentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \n",
       "\n",
       "Here’s a breakdown of what it does and some of the specific details that have come to light:\n",
       "\n",
       "*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\n",
       "    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\n",
       "    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\n",
       "    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\n",
       "    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\n",
       "\n",
       "*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \n",
       "\n",
       "*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\n",
       "\n",
       "*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \n",
       "\n",
       "You can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?\n",
       "Human: What industry was primarily targeted by this malware?\n",
       "AI: That’s a really good question! While LummaC2 has been observed targeting a *variety* of sectors, the technology, gaming, and cryptocurrency industries have been the most heavily targeted. \n",
       "\n",
       "Specifically, it’s been frequently used against companies involved in cryptocurrency – think exchanges and wallet providers – likely to steal digital assets. We've seen a significant amount of activity directed at gaming companies, potentially related to intellectual property theft or financial gain through fraudulent activities. \n",
       "\n",
       "However, it’s important to note that its modular design and reconnaissance capabilities mean it *could* be used against any organization with valuable data, so the targets aren’t limited to just these three. Do you want me to elaborate on the specific tactics they’re using against each of those industries, or perhaps discuss the broader implications of this targeting?'}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           response  \n",
       "0  Oh, LummaC2! That’s a really interesting piece of malware that’s been getting a lot of attention lately. It’s a sophisticated, modular post-exploitation malware developed by the Lazarus Group, which is, in turn, linked to North Korea. \\n\\nEssentially, it’s a reconnaissance and data exfiltration tool. What makes it particularly noteworthy is its incredibly detailed and persistent reconnaissance capabilities. It doesn't just grab a few files; it’s designed to *deeply* understand a compromised network. \\n\\nHere’s a breakdown of what it does and some of the specific details that have come to light:\\n\\n*   **Modular Design:** LummaC2 is built around a modular architecture. This means it’s comprised of several distinct modules, each with a specific function. These modules include:\\n    *   **Credential Dumping:** This is a core function – it actively tries to steal credentials from various systems, including those stored in memory, on local disks, and even within Windows' LSASS process. It's been documented to extract credentials from a wide range of applications like RDP, Skype, and even Microsoft Office.\\n    *   **Webcam Access:** It attempts to activate webcams on compromised systems – often to capture screenshots or even use the webcam for live surveillance.\\n    *   **System Information Gathering:** It collects a massive amount of information about the target system, including hardware details, operating system versions, installed software, network configurations, and user accounts.\\n    *   **Lateral Movement:** Once it has established a foothold, LummaC2 uses this information to move laterally within the network, searching for more valuable targets.\\n\\n*   **Persistence:** A key element of its design is its ability to maintain a persistent presence on the compromised network, even if the initial access vector is removed. It does this by establishing multiple, seemingly legitimate, processes running in the background. \\n\\n*   **Stealth:** The malware is designed to be very stealthy, making it difficult to detect. It uses techniques like process injection and memory manipulation to hide its activities.\\n\\n*   **Recent Activity:** There’s been a surge in LummaC2 activity recently, with reports of it being used in attacks against organizations in the technology, gaming, and cryptocurrency sectors.  Analysts at Mandiant and other cybersecurity firms have been closely tracking its evolution. They've noted changes to its communication protocols and the addition of new modules. \\n\\nYou can find more detailed information about LummaC2 on sites like Mandiant's threat intelligence reports, and on security blogs that cover cyber threat analysis. Do you want me to delve into any particular aspect of it, like the specific communication protocols they use, or perhaps the technical methods employed for stealth?  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                That’s a really good question! While LummaC2 has been observed targeting a *variety* of sectors, the technology, gaming, and cryptocurrency industries have been the most heavily targeted. \\n\\nSpecifically, it’s been frequently used against companies involved in cryptocurrency – think exchanges and wallet providers – likely to steal digital assets. We've seen a significant amount of activity directed at gaming companies, potentially related to intellectual property theft or financial gain through fraudulent activities. \\n\\nHowever, it’s important to note that its modular design and reconnaissance capabilities mean it *could* be used against any organization with valuable data, so the targets aren’t limited to just these three. Do you want me to elaborate on the specific tactics they’re using against each of those industries, or perhaps discuss the broader implications of this targeting?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up conversation memory\n",
    "cbm_memory = ConversationBufferMemory()\n",
    "\n",
    "# Adding memory to a conversational chain\n",
    "chain_with_buffer_memory = ConversationChain(llm=llm, memory=cbm_memory)\n",
    "\n",
    "# Helper function to prompt and print memory state\n",
    "def prompt_and_print_memory(prompts, chain_with_memory):\n",
    "    # Store the responses\n",
    "    responses = {\"input\": [], \"history\": [], \"response\": []}\n",
    "\n",
    "    # Repeatedly prompting the chain and observing the memory\n",
    "    for prompt in prompts:\n",
    "        response = chain_with_memory.invoke({\"input\": prompt})\n",
    "        responses[\"input\"].append(prompt)\n",
    "        responses[\"history\"].append(cbm_memory.load_memory_variables({}))\n",
    "        responses[\"response\"].append(response[\"response\"])\n",
    "\n",
    "    # Display responses in a dataframe\n",
    "    df = pd.DataFrame.from_dict(responses)\n",
    "    with pd.option_context(\"display.max_colwidth\", None):\n",
    "        display(df)\n",
    "\n",
    "# Sequence of prompts for demonstration\n",
    "cbm_prompts = [\n",
    "    \"What is the LummaC2 malware?\",\n",
    "    \"What industry was primarily targeted by this malware?\",\n",
    "]\n",
    "\n",
    "# Invoke helper function\n",
    "prompt_and_print_memory(cbm_prompts, chain_with_buffer_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "### We'll use a tool supplied with LangChain and a custom tool we create\n",
    "\n",
    "[DuckDuckGo](https://duckduckgo.com/) is an internet privacy company most popularly known for their private search engine. The company emphasizes privacy and anonimity as one of the key principles behind all their products.\n",
    "\n",
    "Let's create a DuckDuckGo tool that is capable of retrieving results from a web search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The best-known honey bee species is the western honey bee (Apis mellifera), which was domesticated and farmed (i.e. beekeeping) for honey production and crop pollination. The only other domesticated species is the eastern honey bee (Apis cerana), which are raised in South, Southeast and East Asia. Nov 20, 2025 · A honeybee is any of a small group of social bee s that make honey. All honeybees live together in nests or hives. There are two honeybee sexes, male and female, and two female castes. May 15, 2024 · Honey bee swarms may contain several hundred to several thousand worker bees, a few drones, and one queen. Swarming bees fly around briefly and then cluster on a tree limb, shrub, or another object. Jun 12, 2017 · Bees spend their lives collecting pollen, which provide a source of protein to their developing youngsters. As pollen collects on their hairy legs, they move some of the pollen from the male to the female part of a flower. Simply, a Honey Bee is a small vegetarian insect which lives in a highly structured colony with thousands of its sisters (and a few brothers along with one Queen), all working toward the goal of storing enough food (honey) for the winter when flowers are not present. Oct 17, 2016 · Only one species of honeybee inhabits the United States—the Western Honeybee , Apis mellifera. Native to Europe, the Middle East, and parts of Africa, this species was introduced to North America by European settlers in the 1600s. Honeybees are important pollinators for flowers, fruits, and vegetables . They live on stored honey and pollen all winter and cluster into a ball to conserve warmth. All honeybees are social and... Honeybees live in colonies with one queen running the whole hive. Worker honeybees are all females and are the only bees most people ever see flying around outside of the hive. They forage for food, build the honeycombs, and protect the hive. Oct 17, 2016 · Only one species of honeybee inhabits the United States—the Western Honeybee , Apis mellifera. Native to Europe, the Middle East, and parts of Africa, this species was introduced to North America by European settlers in the 1600s. Lots of people get confused about the difference between bumblebees and honeybees (shown in the photo). Watch our video for a short introduction to the five main differences between these two types of bee . A close-up of a honeybee inspecting the hive cells."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Define the API wrapper for DuckDuckGo search\n",
    "duckduckgo_search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Define the DuckDuckGo tool using a description and the function to retrieve results from DuckDuckGo search\n",
    "duckduckgo_tool = Tool(\n",
    "    name=\"DuckDuckGoSearch\",\n",
    "    func=duckduckgo_search.run,\n",
    "    description=\"useful for when you need to answer questions about current weather and other current events\",\n",
    ")\n",
    "\n",
    "# Test the DuckDuckGo tool\n",
    "Markdown(duckduckgo_tool(\"What is a honeybee?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tools\n",
    "\n",
    "\n",
    "You can define custom tools using the tool decorator.\n",
    "\n",
    "It is critical when writing custom tools that we use well written doc strings, that we use python's type decoration syntax and that we use the @tool decorator supplied by LangChain (loaded above). The docstring and the type labels are used by the agent to reason about what a tool is useful for and how to interface with it. If your agnet isn't picking the correct tools or is calling them incorrectly, these are common culprits.\n",
    "\n",
    "Keep in mind that a custom tool can do anything you can define in code. They can even call APIs of much larger systems. Effectively, these are boundless.\n",
    "\n",
    "Here is a simple custom tool that returns the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from datetime import date\n",
    "\n",
    "@tool\n",
    "def curr_date(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date math should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the date tool\n",
    "date_tool = Tool(\n",
    "    name=\"DateTool\", func=curr_date, description=\"Useful to retrieve the current date\"\n",
    ")\n",
    "\n",
    "# Test date tool\n",
    "print(date_tool(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Finally...we get to the good stuff...Agents are really cool.  Generally speaking, they have a model and a set of tools at their disposal.  They can take a prompt, break it down into the steps necessary to produce a meaningful response and, using the descriptions of the tools at their disposal, decide which ones are likely to be able to accomplish each tasks in the best way.  It then uses it's conclusions to execute the needed tools, pull in the right context and respond to your prompt.\n",
    "\n",
    "They are simple to build and powerful to use.\n",
    "\n",
    "Let's see if we can solve the dot counting problem now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The string contains a series of dots. I need to count the number of dots.\n",
      "Action: Python_REPL\n",
      "Action Input: s = \".....................................\"\n",
      "print(s.count('.'))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m37\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 37\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "37"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from IPython.display import Markdown\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3\",\n",
    "    temperature=0.1,\n",
    "    num_predict=256,  # Use num_predict instead of max_tokens for Ollama\n",
    ")\n",
    "\n",
    "# Define the Python REPL tool\n",
    "python_repl = PythonREPLTool()\n",
    "\n",
    "# Initialize the agent using the local model and the Python REPL tool\n",
    "python_agent = initialize_agent(\n",
    "    [python_repl],\n",
    "    llm,  # Using our previously initialized Ollama Gemma model here\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "# Test the Python Agent with a simple input\n",
    "result = python_agent.invoke(\n",
    "    {\"input\": \"How many dots are in the string ......................................?\"}\n",
    ")\n",
    "\n",
    "# Display the result using Markdown\n",
    "Markdown(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling it all together and let the model reason about something to get the answer we need.\n",
    "\n",
    "### Agent with Automatic Tool Selection\n",
    "The real power of agents is when they are allowed to reason about which tools can be used to solve different tasks or sub-tasks to respond to a prompt. This is what makes them seem intelligent...but remember they are not truly intelligent! They're following sophisticated pattern recognition.\n",
    "\n",
    "The agent reasoning flow works like this:\n",
    "\n",
    "User Input → The user submits a query or request\n",
    "LLM Reasoning → The LLM analyzes the request and determines approach\n",
    "Tool Selection → Based on tool descriptions, the LLM selects appropriate tool(s)\n",
    "Tool Execution → The selected tools are executed with parameters from the LLM\n",
    "Result Synthesis → The LLM combines tool outputs into a coherent response\n",
    "Hopefully, the model decides correctly and you get great results. Sometimes you have to prompt the model to use the right tools.\n",
    "\n",
    "For example, if a model is trying to solve a math problem without using your math-specific tool, you can just add \"You are bad at math so always use the wolfram tool to solve math problems\" in the prompt. Simple guidance like this is usually enough to get the model working the way you intend.\n",
    "\n",
    "This reasoning ability to select appropriate tools creates a flexible system that can handle diverse queries by combining specialized tools with general language understanding. The agent can break down complex problems, identify which tools would be most helpful for each component, and then integrate the results into a coherent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# Define a list of available tools for the agent\n",
    "tools = [\n",
    "    duckduckgo_tool,\n",
    "    date_tool,\n",
    "]\n",
    "\n",
    "# Initialize the agent with access to all the tooks in the list\n",
    "agent_executor = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the weather in Washington DC today to determine if I need an umbrella. Since the date was not specified, I should use the DateTool to get today's date and then use the DuckDuckGoSearch tool to find the weather for that date.\n",
      "Action: DateTool\n",
      "Action Input: ''\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m2025-12-04\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mOkay, I now have today's date as 2025-12-04. I will use the DuckDuckGoSearch tool to find the weather in Washington DC for this date.\n",
      "Action: DuckDuckGoSearch\n",
      "Action Input: 'weather Washington DC 2025-12-04'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mWashington , DC 39°F Cloudy- Light rain is expected. ... Delightful, is there generally a big difference in weather between S Scotland and the ... Washington , DC Weather ... 10 Day Weather - Washington , DC ... NFL 2025 Schedule: The Hottest, Coldest, Wettest, Snowiest Games The Weather Channel uses data, cookies and other similar technologies on this browser to optimise our website, and to provide you with weather ... On Friday, in Washington , sunrise will be at 7:10 am and sunset at 4:47 pm (EST). ... Updated: Dec 4, 2025 @ 22:17:39 UTC Published by: Weather U.S. Washington weather tomorrow and 5 day forecast with this week's outlook providing reliable day and night reports including precipitation, high and ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the weather in Washington DC on 2025-12-04 is Cloudy- Light rain is expected.\n",
      "Final Answer: Cloudy- Light rain is expected.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"\\n        System: You are not good at determining dates and times.  When you are asked about weather reports, you should first make sure you know what date is being asked about.\\n        If you are asked about weather and a day was not specified, you should use the date_tool to get today's date and then use the duckduckgo_tool to find out the weather for the date.\\n        When asking about weather, you should always include the date in your search for weather so you get the weather report for the correct date.\\n\\n        Human: I am in Washington DC.  Will I need an umbrella today?\\n        \",\n",
       " 'output': 'Cloudy- Light rain is expected.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"\"\"\n",
    "        System: You are not good at determining dates and times.  When you are asked about weather reports, you should first make sure you know what date is being asked about.\n",
    "        If you are asked about weather and a day was not specified, you should use the date_tool to get today's date and then use the duckduckgo_tool to find out the weather for the date.\n",
    "        When asking about weather, you should always include the date in your search for weather so you get the weather report for the correct date.\n",
    "        \n",
    "        Human: I am in Washington DC.  Will I need an umbrella today?\n",
    "        \"\"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Demonstration with ChromaDB\n",
    "\n",
    "This cell demonstrates building a Retrieval-Augmented Generation (RAG) system using ChromaDB as the vector store. The code loads PDF documents, splits them into manageable chunks, creates vector embeddings using AWS Bedrock or HuggingFace models, and stores them in a persistent ChromaDB database. It showcases two key RAG functionalities: (1) direct similarity search to retrieve relevant document chunks based on semantic meaning, and (2) question answering that leverages the retrieved context to generate accurate responses using an LLM. This implementation includes fallback options, proper error handling, and performance testing to ensure reliable operation even if the primary embedding service encounters issues. The system persists the vector database to disk, allowing for reuse without regenerating embeddings in future sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF directory is at: /Users/schwartz/src/genai-essentials/data/pdfs\n",
      "\n",
      "Question: What is LummaC2?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I don't know. The provided context discusses securing remote access software and incident root cause analysis, but it does not contain information about LummaC2."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sources:\n",
      "clickfix-attacks-sector-alert-tlpclear.pdf, Page 1\n",
      "\n",
      "Question: What is a ClickFix?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I don’t know. The provided context does not contain information about ClickFix."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sources:\n",
      "clickfix-attacks-sector-alert-tlpclear.pdf, Page 1\n",
      "\n",
      "Question: Why is the sky blue?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I do not know. The provided context discusses IT and OT network configurations and cloud portals, not the reason why the sky is blue."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sources:\n",
      "ts_10399402v010101p.pdf, Page 9\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize Ollama LLM (Gemma model)\n",
    "# Make sure these are pulled once:\n",
    "#   ollama pull gemma3\n",
    "#   ollama pull nomic-embed-text\n",
    "llm = Ollama(\n",
    "    model=\"gemma3\",\n",
    "    base_url=\"http://localhost:11434\",     # explicit, just to be clear\n",
    ")\n",
    "\n",
    "# 🔧 Embeddings model: add num_ctx and base_url\n",
    "embedding_model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    num_ctx=2048,     # <= keep context modest to avoid crashes\n",
    "    # you could even try 1024 if needed\n",
    ")\n",
    "\n",
    "# Create directory for PDFs\n",
    "pdf_dir = \"./data/pdfs\"\n",
    "os.makedirs(pdf_dir, exist_ok=True)\n",
    "print(f\"PDF directory is at: {os.path.abspath(pdf_dir)}\")\n",
    "\n",
    "# 🔧 Text splitter: smaller chunks\n",
    "recur_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,        # was 1000\n",
    "    chunk_overlap=100,     # was 200\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Load and process PDFs using PyMuPDFLoader for each file in the directory\n",
    "data = []\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        loader = PyMuPDFLoader(file_path=os.path.join(pdf_dir, filename))\n",
    "        data.extend(loader.load())\n",
    "\n",
    "# Ensure there's data, create a demo if not\n",
    "if len(data) == 0:\n",
    "    data = [\n",
    "        Document(\n",
    "            page_content=\"Sample text about LummaC2.\",\n",
    "            metadata={\"source\": \"sample.pdf\", \"page\": 1},\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "# Split documents into chunks\n",
    "data_splits = recur_splitter.split_documents(data)\n",
    "\n",
    "# (Optional but helpful debug: quickly sanity-check chunks)\n",
    "# for i, d in enumerate(data_splits[:3]):\n",
    "#     print(i, len(d.page_content))\n",
    "\n",
    "# Create ChromaDB vector store (persists locally)\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=data_splits,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"rag-demo\",\n",
    "    persist_directory=\"./chroma_llm_training\"\n",
    ")\n",
    "\n",
    "# Define RAG QA prompt template\n",
    "qa_template = \"\"\"\n",
    "You are a helpful assistant answering questions based on the provided context.\n",
    "Use the following pieces of context to answer the user's question. If unsure, state you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "qa_prompt_template = PromptTemplate.from_template(qa_template)\n",
    "\n",
    "# Define RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": qa_prompt_template},\n",
    ")\n",
    "\n",
    "# Test questions\n",
    "questions = [\n",
    "    \"What is LummaC2?\",\n",
    "    \"What is a ClickFix?\",\n",
    "    \"Why is the sky blue?\"\n",
    "]\n",
    "\n",
    "# Run questions through the QA chain\n",
    "for question in questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    response = qa_chain({\"query\": question})\n",
    "    display(Markdown(response[\"result\"]))\n",
    "\n",
    "    print(\"\\nSources:\")\n",
    "    seen_sources = set()\n",
    "    for doc in response[\"source_documents\"][:2]:\n",
    "        source_info = f\"{os.path.basename(doc.metadata['source'])}, Page {doc.metadata.get('page', 'N/A')}\"\n",
    "        if source_info not in seen_sources:\n",
    "            print(source_info)\n",
    "            seen_sources.add(source_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
